{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba16d5b",
   "metadata": {},
   "source": [
    "## Bronze Test\n",
    "\n",
    "Verifying whether `01_bronze_ingest.py` works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60fb83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = (\n",
    "    spark.read\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"pkc-619z3.us-east1.gcp.confluent.cloud:9092\")\n",
    "    .option(\"kafka.security.protocol\", \"SASL_SSL\")\n",
    "    .option(\"kafka.sasl.mechanism\", \"PLAIN\")\n",
    "    .option(\n",
    "        \"kafka.sasl.jaas.config\",\n",
    "        'org.apache.kafka.common.security.plain.PlainLoginModule required '\n",
    "        'username=\"5OKF4XEW3FYOEXB2\" '\n",
    "        'password=\"cfltyrd+JQr0IqzcutgiYR4bq02tbVcsON6rVjG8qHAjMQlbjOlEqJWVhjlhP4JA\";'\n",
    "    )\n",
    "    .option(\"subscribe\", \"school_climate_stream\")\n",
    "    .option(\"startingOffsets\", \"earliest\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "print(\"Connected to Kafka, schema:\")\n",
    "test_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e176d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rt_databricks.utils.gcs_paths import bronze_path, checkpoint_path\n",
    "\n",
    "bronze_uri = bronze_path(\"school_climate_raw\")\n",
    "chk_uri = checkpoint_path(\"kafka_school_climate_bronze\")\n",
    "\n",
    "kafka_df = (\n",
    "    spark.readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"pkc-619z3.us-east1.gcp.confluent.cloud:9092\")\n",
    "    .option(\"kafka.security.protocol\", \"SASL_SSL\")\n",
    "    .option(\"kafka.sasl.mechanism\", \"PLAIN\")\n",
    "    .option(\n",
    "        \"kafka.sasl.jaas.config\",\n",
    "        'org.apache.kafka.common.security.plain.PlainLoginModule required '\n",
    "        'username=\"5OKF4XEW3FYOEXB2\" '\n",
    "        'password=\"cfltyrd+JQr0IqzcutgiYR4bq02tbVcsON6rVjG8qHAjMQlbjOlEqJWVhjlhP4JA\";'\n",
    "    )\n",
    "    .option(\"subscribe\", \"school_climate_stream\")\n",
    "    .option(\"startingOffsets\", \"earliest\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "bronze_df = (\n",
    "    kafka_df\n",
    "    .selectExpr(\n",
    "        \"CAST(key AS STRING) AS key\",\n",
    "        \"CAST(value AS STRING) AS value\",\n",
    "        \"topic\",\n",
    "        \"partition\",\n",
    "        \"offset\",\n",
    "        \"timestamp\",\n",
    "        \"timestampType\"\n",
    "    )\n",
    ")\n",
    "\n",
    "query = (\n",
    "    bronze_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .option(\"checkpointLocation\", chk_uri)\n",
    "    .option(\"path\", bronze_uri)\n",
    "    .outputMode(\"append\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "print(\"Direct streaming Bronze started\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
